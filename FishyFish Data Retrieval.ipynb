{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve Data for FishyFish Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from importlib import reload\n",
    "import os\n",
    "import pickle\n",
    "import fish_data as fd\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from scipy import misc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load label_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('label_dictionary.pickle', 'rb') as handle :\n",
    "    label_dictionary = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3777\n"
     ]
    }
   ],
   "source": [
    "print(len(label_dictionary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create DataFrame of annotated fovea embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = pd.DataFrame([], columns = ['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT', 'NoF'], index = [])\n",
    "box_preds = pd.DataFrame([], columns = ['scale', 'y_offset', 'x_offset'], index = [])\n",
    "annotated_boxes = pd.DataFrame([], columns = ['scale', 'y_offset', 'x_offset'], index = [])\n",
    "FiNoF_prob = pd.Series([], index = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in list(label_dictionary.keys()) :\n",
    "    #print(label_dictionary.get(key))\n",
    "    #print(np.expand_dims(label_dictionary.get(key).get('box_preds'), 0))\n",
    "    labels = labels.append(pd.DataFrame(label_dictionary.get(key).get('onehot'), index = [key], columns =['ALB', 'BET', 'DOL', 'LAG', 'OTHER', 'SHARK', 'YFT', 'NoF']) )\n",
    "    box_preds = box_preds.append( pd.DataFrame(np.expand_dims(label_dictionary.get(key).get('box_preds'), 0), index = [key] , columns = ['scale', 'y_offset', 'x_offset'] ))\n",
    "    \n",
    "    if label_dictionary.get(key).get('scale') is not None :\n",
    "        annotated_boxes = annotated_boxes.append(pd.DataFrame(np.expand_dims(np.concatenate([label_dictionary.get(key).get('scale'),label_dictionary.get(key).get('coord') ], 0),0), \n",
    "                                                             columns = ['scale', 'y_offset', 'x_offset'], index = [key]))\n",
    "    FiNoF_prob = FiNoF_prob.append(pd.Series(label_dictionary.get(key).get('FiNoF'), index = [key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3777, 32)\n"
     ]
    }
   ],
   "source": [
    "embedding_df = pd.read_pickle('embedding_dataframe.pickle')\n",
    "print(embedding_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels.to_pickle('onehot_df.pickle')\n",
    "box_preds.to_pickle('box_preds.pickle')\n",
    "annotated_boxes.to_pickle('annotated_boxes.pickle')\n",
    "FiNoF_prob.to_pickle('FiNoF_prob.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Store Annotated Fovea in appropriate directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in list(label_dictionary.keys()) :\n",
    "    if label_dictionary.get(key).get('scale') is not None :\n",
    "        scale = label_dictionary.get(key).get('scale')\n",
    "        yxcoord = label_dictionary.get(key).get('coord')\n",
    "        fov = fd.retrieve_fovea(key, yxcoord, scale[0], fov_dim = 72)\n",
    "        new_path = 'data/annotated_fovea_train/'+key[11:]\n",
    "        misc.imsave(new_path, fov, format = 'JPEG' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store Predicted Fovea in appropriate directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in list(label_dictionary.keys()) :\n",
    "    box = label_dictionary.get(key).get('box_preds')\n",
    "    scale = box[0]\n",
    "    yxcoord = box[1:]\n",
    "    fov = fd.retrieve_fovea(key, yxcoord, scale, fov_dim = 72)\n",
    "    new_path = 'data/predicted_fovea_train/'+key[11:]\n",
    "    misc.imsave(new_path, fov, format = 'JPEG' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALB', 'BET', 'DOL', 'LAG', 'NoF', 'OTHER', 'SHARK', 'YFT']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data/annotated_fovea_train/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Stage 2 Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get all filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12154\n"
     ]
    }
   ],
   "source": [
    "test_fnames = fd.generate_filenames_list('data/test_stg2/', False)\n",
    "print(len(test_fnames))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12153\n"
     ]
    }
   ],
   "source": [
    "test_fnames.remove('data/test_stg2/.DS_Store')\n",
    "print(len(test_fnames))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run through FishFinder and store FiNoF , box specs in pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "version_ID = 'v1.2'\n",
    "initiate_FishFinder = False \n",
    "\n",
    "wd = os.getcwd()\n",
    "md = wd+'/FishFinder/'+version_ID\n",
    "if not os.path.exists(md) :\n",
    "    os.makedirs(md)\n",
    "tensorboard_path = md+'/Tensorboard_logs'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i 'FishFinder/FishFinder_PARAMS.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%run -i 'FishFinder/FishFinder_GRAPH.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading FishFinder_MT version v1.2\n",
      "Metadata dictionary loaded!\n",
      "Initializing restorer...\n",
      "Weights and biases retrieved!  Picking up at 665 epochs completed : 2230912 training images observed\n",
      "Running Predictor on Test Stage 2 images...\n",
      "0 images embedded\n",
      "Length of prediction_keys : 12025\n",
      "1024 images embedded\n",
      "Length of prediction_keys : 11001\n",
      "2048 images embedded\n",
      "Length of prediction_keys : 9977\n",
      "3072 images embedded\n",
      "Length of prediction_keys : 8953\n",
      "4096 images embedded\n",
      "Length of prediction_keys : 7929\n",
      "5120 images embedded\n",
      "Length of prediction_keys : 6905\n",
      "6144 images embedded\n",
      "Length of prediction_keys : 5881\n",
      "7168 images embedded\n",
      "Length of prediction_keys : 4857\n",
      "8192 images embedded\n",
      "Length of prediction_keys : 3833\n",
      "9216 images embedded\n",
      "Length of prediction_keys : 2809\n",
      "10240 images embedded\n",
      "Length of prediction_keys : 1785\n",
      "11264 images embedded\n",
      "Length of prediction_keys : 761\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 121 is out of bounds for axis 0 with size 121",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Users/ccthomps/Documents/ML_Projects/Kaggle Competitions/FF3/FishFinder/FishFinder_GRAPH.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mt_FiNoF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFiNoF_Probability\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0mt_box_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBox_Predictions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mt_embedding_arr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoarse_embedding\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 121 is out of bounds for axis 0 with size 121"
     ]
    }
   ],
   "source": [
    "with tf.Session(graph = fish_finder) as session :\n",
    "    if 'meta_dictionary.pickle' in os.listdir(md) and initiate_FishFinder != True:\n",
    "        print(\"Loading FishFinder_MT version {}\".format(version_ID))\n",
    "        with open(md+'/meta_dictionary.pickle', 'rb') as  handle :\n",
    "            meta_dict = pickle.load(handle)\n",
    "        print(\"Metadata dictionary loaded!\")\n",
    "        total_fovea = meta_dict.get(np.max([key for key in meta_dict])).get('fovea_trained')\n",
    "        epochs_completed = meta_dict.get(np.max([key for key in meta_dict])).get('Num_epochs')\n",
    "        restorer = tf.train.Saver()\n",
    "        print(\"Initializing restorer...\")\n",
    "        restorer.restore(session, tf.train.latest_checkpoint(md))\n",
    "        print(\"Weights and biases retrieved!  Picking up at {} epochs completed : {} training images observed\".format(epochs_completed, total_fovea))\n",
    "    print(\"Running Predictor on Test Stage 2 images...\")\n",
    "    \n",
    "    keys_list = test_fnames.copy()\n",
    "    t_embedding_arr = np.zeros([len(keys_list), 32])\n",
    "    t_FiNoF = np.zeros([len(keys_list), 1])\n",
    "    t_box_preds = np.zeros([len(keys_list),3])\n",
    "    cursor = 0\n",
    "    while len(keys_list) > batch_size :\n",
    "        for i in range(batch_size) :\n",
    "            coarse = misc.imresize(misc.imread(keys_list.pop(0), mode = 'RGB'), size = [64, 112,3], mode = 'RGB')\n",
    "            if i == 0 :\n",
    "                coarse_arr = np.expand_dims(coarse, 0)\n",
    "            else :\n",
    "                coarse_arr = np.concatenate([coarse_arr, np.expand_dims(coarse,0)], 0)\n",
    "        \n",
    "        feed_dict = {coarse_images_for_prediction : coarse_arr}\n",
    "        FiNoF_Probability, Box_Predictions, coarse_embedding = session.run([stack_FishNoF_preds, stack_box_preds, stack_dense_output], feed_dict = feed_dict)\n",
    "        \n",
    "        for i in range(batch_size) :\n",
    "            t_FiNoF[cursor, :] = FiNoF_Probability[i]\n",
    "            t_box_preds[cursor, :] = Box_Predictions[i,:]\n",
    "            t_embedding_arr[cursor, :] = coarse_embedding[i, :]\n",
    "            if (cursor % 1024) == 0 :\n",
    "                print(\"{} images embedded\".format(cursor))\n",
    "                print(\"Length of prediction_keys : {}\".format(len(keys_list)))\n",
    "            cursor += 1\n",
    "                \n",
    "    for i in range(len(keys_list)) :\n",
    "        coarse = misc.imresize(misc.imread(keys_list.pop(0), mode = 'RGB'), size = [64, 112,3], mode = 'RGB')\n",
    "        if i == 0 :\n",
    "            coarse_arr = np.expand_dims(coarse, 0)\n",
    "        else :\n",
    "            coarse_arr = np.concatenate([coarse_arr, np.expand_dims(coarse,0)], 0)\n",
    "        \n",
    "    feed_dict = {coarse_images_for_prediction : coarse_arr}\n",
    "    FiNoF_Probability, Box_Predictions, coarse_embedding = session.run([stack_FishNoF_preds, stack_box_preds, stack_dense_output], feed_dict = feed_dict)\n",
    "\n",
    "    for i in range(batch_size) :\n",
    "        t_FiNoF[cursor, :] = FiNoF_Probability[i]\n",
    "        t_box_preds[cursor, :] = Box_Predictions[i,:]\n",
    "        t_embedding_arr[cursor, :] = coarse_embedding[i, :]\n",
    "        cursor += 1\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that is ok.  Made mistake in number of iterations for the final garbage loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12153, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_FiNoF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12153, 3)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_box_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12153, 32)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_embedding_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                   FiNoF\n",
      "data/test_stg2/image_00001.jpg  0.841103\n",
      "data/test_stg2/image_00002.jpg  0.882154\n",
      "data/test_stg2/image_00003.jpg  0.833156\n",
      "data/test_stg2/image_00004.jpg  0.626342\n",
      "data/test_stg2/image_00005.jpg  0.810221\n"
     ]
    }
   ],
   "source": [
    "t_FiNoF_df = pd.DataFrame(t_FiNoF, columns = ['FiNoF'], index = test_fnames.copy())\n",
    "print(t_FiNoF_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_box_preds_df = pd.DataFrame(t_box_preds, columns = ['scale', 'y_off', 'x_off'], index = test_fnames.copy())\n",
    "t_embedding_df = pd.DataFrame(t_embedding_arr, columns = list(range(32)), index = test_fnames.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00001.jpg</th>\n",
       "      <td>-0.758492</td>\n",
       "      <td>-0.889309</td>\n",
       "      <td>-0.759618</td>\n",
       "      <td>-0.271521</td>\n",
       "      <td>0.825022</td>\n",
       "      <td>-0.988796</td>\n",
       "      <td>-0.996101</td>\n",
       "      <td>-0.845239</td>\n",
       "      <td>0.820566</td>\n",
       "      <td>-0.472032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.835609</td>\n",
       "      <td>0.999243</td>\n",
       "      <td>0.999910</td>\n",
       "      <td>-0.878443</td>\n",
       "      <td>0.984017</td>\n",
       "      <td>-0.716900</td>\n",
       "      <td>0.949253</td>\n",
       "      <td>0.967637</td>\n",
       "      <td>0.468045</td>\n",
       "      <td>-0.937420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00002.jpg</th>\n",
       "      <td>-0.997257</td>\n",
       "      <td>0.828025</td>\n",
       "      <td>-0.982014</td>\n",
       "      <td>-0.590100</td>\n",
       "      <td>0.754886</td>\n",
       "      <td>-0.956849</td>\n",
       "      <td>-0.990188</td>\n",
       "      <td>0.502840</td>\n",
       "      <td>0.999367</td>\n",
       "      <td>-0.892620</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.945684</td>\n",
       "      <td>0.999979</td>\n",
       "      <td>0.998693</td>\n",
       "      <td>-0.995464</td>\n",
       "      <td>0.208390</td>\n",
       "      <td>-0.346967</td>\n",
       "      <td>0.877636</td>\n",
       "      <td>-0.783396</td>\n",
       "      <td>-0.995806</td>\n",
       "      <td>-0.997825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00003.jpg</th>\n",
       "      <td>-0.982845</td>\n",
       "      <td>0.130662</td>\n",
       "      <td>-0.299713</td>\n",
       "      <td>-0.942765</td>\n",
       "      <td>-0.771721</td>\n",
       "      <td>-0.999010</td>\n",
       "      <td>-0.947415</td>\n",
       "      <td>-0.063972</td>\n",
       "      <td>0.998624</td>\n",
       "      <td>-0.452502</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.971590</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>-0.917787</td>\n",
       "      <td>0.133872</td>\n",
       "      <td>-0.615132</td>\n",
       "      <td>0.998438</td>\n",
       "      <td>0.743631</td>\n",
       "      <td>-0.993690</td>\n",
       "      <td>-0.984879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00004.jpg</th>\n",
       "      <td>-0.424008</td>\n",
       "      <td>-0.979936</td>\n",
       "      <td>0.533171</td>\n",
       "      <td>-0.358645</td>\n",
       "      <td>0.336902</td>\n",
       "      <td>-0.641456</td>\n",
       "      <td>-0.942020</td>\n",
       "      <td>-0.965239</td>\n",
       "      <td>-0.233703</td>\n",
       "      <td>0.469364</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.993246</td>\n",
       "      <td>0.986702</td>\n",
       "      <td>0.972661</td>\n",
       "      <td>-0.131879</td>\n",
       "      <td>-0.275115</td>\n",
       "      <td>-0.932732</td>\n",
       "      <td>0.802958</td>\n",
       "      <td>-0.441994</td>\n",
       "      <td>-0.854718</td>\n",
       "      <td>-0.999425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00005.jpg</th>\n",
       "      <td>-0.975280</td>\n",
       "      <td>0.503223</td>\n",
       "      <td>-0.484824</td>\n",
       "      <td>-0.941582</td>\n",
       "      <td>0.791352</td>\n",
       "      <td>-0.946153</td>\n",
       "      <td>-0.771835</td>\n",
       "      <td>-0.976238</td>\n",
       "      <td>0.789828</td>\n",
       "      <td>0.318252</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.591972</td>\n",
       "      <td>0.999536</td>\n",
       "      <td>0.999898</td>\n",
       "      <td>-0.451718</td>\n",
       "      <td>0.943795</td>\n",
       "      <td>-0.945395</td>\n",
       "      <td>0.665864</td>\n",
       "      <td>0.384008</td>\n",
       "      <td>-0.997119</td>\n",
       "      <td>-0.996266</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0         1         2         3   \\\n",
       "data/test_stg2/image_00001.jpg -0.758492 -0.889309 -0.759618 -0.271521   \n",
       "data/test_stg2/image_00002.jpg -0.997257  0.828025 -0.982014 -0.590100   \n",
       "data/test_stg2/image_00003.jpg -0.982845  0.130662 -0.299713 -0.942765   \n",
       "data/test_stg2/image_00004.jpg -0.424008 -0.979936  0.533171 -0.358645   \n",
       "data/test_stg2/image_00005.jpg -0.975280  0.503223 -0.484824 -0.941582   \n",
       "\n",
       "                                      4         5         6         7   \\\n",
       "data/test_stg2/image_00001.jpg  0.825022 -0.988796 -0.996101 -0.845239   \n",
       "data/test_stg2/image_00002.jpg  0.754886 -0.956849 -0.990188  0.502840   \n",
       "data/test_stg2/image_00003.jpg -0.771721 -0.999010 -0.947415 -0.063972   \n",
       "data/test_stg2/image_00004.jpg  0.336902 -0.641456 -0.942020 -0.965239   \n",
       "data/test_stg2/image_00005.jpg  0.791352 -0.946153 -0.771835 -0.976238   \n",
       "\n",
       "                                      8         9     ...           22  \\\n",
       "data/test_stg2/image_00001.jpg  0.820566 -0.472032    ...    -0.835609   \n",
       "data/test_stg2/image_00002.jpg  0.999367 -0.892620    ...    -0.945684   \n",
       "data/test_stg2/image_00003.jpg  0.998624 -0.452502    ...    -0.971590   \n",
       "data/test_stg2/image_00004.jpg -0.233703  0.469364    ...    -0.993246   \n",
       "data/test_stg2/image_00005.jpg  0.789828  0.318252    ...    -0.591972   \n",
       "\n",
       "                                      23        24        25        26  \\\n",
       "data/test_stg2/image_00001.jpg  0.999243  0.999910 -0.878443  0.984017   \n",
       "data/test_stg2/image_00002.jpg  0.999979  0.998693 -0.995464  0.208390   \n",
       "data/test_stg2/image_00003.jpg  0.999959  0.999806 -0.917787  0.133872   \n",
       "data/test_stg2/image_00004.jpg  0.986702  0.972661 -0.131879 -0.275115   \n",
       "data/test_stg2/image_00005.jpg  0.999536  0.999898 -0.451718  0.943795   \n",
       "\n",
       "                                      27        28        29        30  \\\n",
       "data/test_stg2/image_00001.jpg -0.716900  0.949253  0.967637  0.468045   \n",
       "data/test_stg2/image_00002.jpg -0.346967  0.877636 -0.783396 -0.995806   \n",
       "data/test_stg2/image_00003.jpg -0.615132  0.998438  0.743631 -0.993690   \n",
       "data/test_stg2/image_00004.jpg -0.932732  0.802958 -0.441994 -0.854718   \n",
       "data/test_stg2/image_00005.jpg -0.945395  0.665864  0.384008 -0.997119   \n",
       "\n",
       "                                      31  \n",
       "data/test_stg2/image_00001.jpg -0.937420  \n",
       "data/test_stg2/image_00002.jpg -0.997825  \n",
       "data/test_stg2/image_00003.jpg -0.984879  \n",
       "data/test_stg2/image_00004.jpg -0.999425  \n",
       "data/test_stg2/image_00005.jpg -0.996266  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_embedding_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scale</th>\n",
       "      <th>y_off</th>\n",
       "      <th>x_off</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00001.jpg</th>\n",
       "      <td>0.288571</td>\n",
       "      <td>0.227286</td>\n",
       "      <td>0.219619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00002.jpg</th>\n",
       "      <td>0.245040</td>\n",
       "      <td>0.426259</td>\n",
       "      <td>0.244950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00003.jpg</th>\n",
       "      <td>0.314292</td>\n",
       "      <td>0.205844</td>\n",
       "      <td>0.205153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00004.jpg</th>\n",
       "      <td>0.413568</td>\n",
       "      <td>0.273896</td>\n",
       "      <td>0.397684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data/test_stg2/image_00005.jpg</th>\n",
       "      <td>0.279387</td>\n",
       "      <td>0.369376</td>\n",
       "      <td>0.198613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   scale     y_off     x_off\n",
       "data/test_stg2/image_00001.jpg  0.288571  0.227286  0.219619\n",
       "data/test_stg2/image_00002.jpg  0.245040  0.426259  0.244950\n",
       "data/test_stg2/image_00003.jpg  0.314292  0.205844  0.205153\n",
       "data/test_stg2/image_00004.jpg  0.413568  0.273896  0.397684\n",
       "data/test_stg2/image_00005.jpg  0.279387  0.369376  0.198613"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_box_preds_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t_FiNoF_df.to_pickle('test_FiNoF_dataframe.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_embedding_df.to_pickle('test_embeddings_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_box_preds_df.to_pickle('test_box_preds_df.pickle')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Fovea for Test Stage 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for key in test_fnames :\n",
    "    scale = t_box_preds_df['scale'].loc[key]\n",
    "    yxcoord = np.array(t_box_preds_df.loc[key, ['y_off', 'x_off']])\n",
    "\n",
    "    fov = fd.retrieve_fovea(key, yxcoord, scale, fov_dim = 72)\n",
    "    new_path = 'data/predicted_fovea_test_stg2/'+key[15:]\n",
    "\n",
    "    misc.imsave(new_path, fov, format = 'JPEG' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data/test_stg2/image_12153.jpg'"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'img_12153.jpg'"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'img'+key[20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
